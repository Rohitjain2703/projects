{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4924ab6",
   "metadata": {},
   "source": [
    "# xtrame gradient boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing xgboost using ancoanda promt\n",
    "# conda install -c anaconda py-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7878531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\rohit jain\\anaconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\rohit jain\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\rohit jain\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "#install xgboost using jyputer\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db128212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45624414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class cap-shape cap-surface cap-color bruises odor gill-attachment  \\\n",
       "0     p         x           s         n       t    p               f   \n",
       "1     e         x           s         y       t    a               f   \n",
       "2     e         b           s         w       t    l               f   \n",
       "3     p         x           y         w       t    p               f   \n",
       "4     e         x           s         g       f    n               f   \n",
       "\n",
       "  gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "0            c         n          k  ...                        s   \n",
       "1            c         b          k  ...                        s   \n",
       "2            c         b          n  ...                        s   \n",
       "3            c         n          n  ...                        s   \n",
       "4            w         b          k  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=pd.read_csv(\"Downloads\\mushrooms.csv\")\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc98ae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bcbc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Eda\n",
    "sns.countplot(x=\"class\",data=ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8853772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>...</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4208</td>\n",
       "      <td>3656</td>\n",
       "      <td>3244</td>\n",
       "      <td>2284</td>\n",
       "      <td>4748</td>\n",
       "      <td>3528</td>\n",
       "      <td>7914</td>\n",
       "      <td>6812</td>\n",
       "      <td>5612</td>\n",
       "      <td>1728</td>\n",
       "      <td>...</td>\n",
       "      <td>4936</td>\n",
       "      <td>4464</td>\n",
       "      <td>4384</td>\n",
       "      <td>8124</td>\n",
       "      <td>7924</td>\n",
       "      <td>7488</td>\n",
       "      <td>3968</td>\n",
       "      <td>2388</td>\n",
       "      <td>4040</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
       "count   8124      8124        8124      8124    8124  8124            8124   \n",
       "unique     2         6           4        10       2     9               2   \n",
       "top        e         x           y         n       f     n               f   \n",
       "freq    4208      3656        3244      2284    4748  3528            7914   \n",
       "\n",
       "       gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "count          8124      8124       8124  ...                     8124   \n",
       "unique            2         2         12  ...                        4   \n",
       "top               c         b          b  ...                        s   \n",
       "freq           6812      5612       1728  ...                     4936   \n",
       "\n",
       "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "count                    8124                   8124      8124       8124   \n",
       "unique                      9                      9         1          4   \n",
       "top                         w                      w         p          w   \n",
       "freq                     4464                   4384      8124       7924   \n",
       "\n",
       "       ring-number ring-type spore-print-color population habitat  \n",
       "count         8124      8124              8124       8124    8124  \n",
       "unique           3         5                 9          6       7  \n",
       "top              o         p                 w          v       d  \n",
       "freq          7488      3968              2388       4040    3148  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e30371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>e</td>\n",
       "      <td>4208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-shape</th>\n",
       "      <td>8124</td>\n",
       "      <td>6</td>\n",
       "      <td>x</td>\n",
       "      <td>3656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-surface</th>\n",
       "      <td>8124</td>\n",
       "      <td>4</td>\n",
       "      <td>y</td>\n",
       "      <td>3244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cap-color</th>\n",
       "      <td>8124</td>\n",
       "      <td>10</td>\n",
       "      <td>n</td>\n",
       "      <td>2284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bruises</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>4748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odor</th>\n",
       "      <td>8124</td>\n",
       "      <td>9</td>\n",
       "      <td>n</td>\n",
       "      <td>3528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-attachment</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>f</td>\n",
       "      <td>7914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-spacing</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>6812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-size</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>5612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gill-color</th>\n",
       "      <td>8124</td>\n",
       "      <td>12</td>\n",
       "      <td>b</td>\n",
       "      <td>1728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-shape</th>\n",
       "      <td>8124</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>4608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-root</th>\n",
       "      <td>8124</td>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "      <td>3776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <td>8124</td>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>5176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <td>8124</td>\n",
       "      <td>4</td>\n",
       "      <td>s</td>\n",
       "      <td>4936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <td>8124</td>\n",
       "      <td>9</td>\n",
       "      <td>w</td>\n",
       "      <td>4464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <td>8124</td>\n",
       "      <td>9</td>\n",
       "      <td>w</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil-type</th>\n",
       "      <td>8124</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>veil-color</th>\n",
       "      <td>8124</td>\n",
       "      <td>4</td>\n",
       "      <td>w</td>\n",
       "      <td>7924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring-number</th>\n",
       "      <td>8124</td>\n",
       "      <td>3</td>\n",
       "      <td>o</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ring-type</th>\n",
       "      <td>8124</td>\n",
       "      <td>5</td>\n",
       "      <td>p</td>\n",
       "      <td>3968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spore-print-color</th>\n",
       "      <td>8124</td>\n",
       "      <td>9</td>\n",
       "      <td>w</td>\n",
       "      <td>2388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>8124</td>\n",
       "      <td>6</td>\n",
       "      <td>v</td>\n",
       "      <td>4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>habitat</th>\n",
       "      <td>8124</td>\n",
       "      <td>7</td>\n",
       "      <td>d</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count unique top  freq\n",
       "class                     8124      2   e  4208\n",
       "cap-shape                 8124      6   x  3656\n",
       "cap-surface               8124      4   y  3244\n",
       "cap-color                 8124     10   n  2284\n",
       "bruises                   8124      2   f  4748\n",
       "odor                      8124      9   n  3528\n",
       "gill-attachment           8124      2   f  7914\n",
       "gill-spacing              8124      2   c  6812\n",
       "gill-size                 8124      2   b  5612\n",
       "gill-color                8124     12   b  1728\n",
       "stalk-shape               8124      2   t  4608\n",
       "stalk-root                8124      5   b  3776\n",
       "stalk-surface-above-ring  8124      4   s  5176\n",
       "stalk-surface-below-ring  8124      4   s  4936\n",
       "stalk-color-above-ring    8124      9   w  4464\n",
       "stalk-color-below-ring    8124      9   w  4384\n",
       "veil-type                 8124      1   p  8124\n",
       "veil-color                8124      4   w  7924\n",
       "ring-number               8124      3   o  7488\n",
       "ring-type                 8124      5   p  3968\n",
       "spore-print-color         8124      9   w  2388\n",
       "population                8124      6   v  4040\n",
       "habitat                   8124      7   d  3148"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c55b51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xnad y \n",
    "x=pd.get_dummies(ds.drop(\"class\",axis=1),drop_first=True)\n",
    "y=pd.get_dummies(ds[\"class\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4251db2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8124, 95), (8124, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f235034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32b63c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling xgboost with defult \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b002c260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class XGBClassifier in module xgboost.sklearn:\n",
      "\n",
      "class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      " |  XGBClassifier(*, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', use_label_encoder: Optional[bool] = None, **kwargs: Any) -> None\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for XGBoost classification.\n",
      " |  \n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |      n_estimators : int\n",
      " |          Number of boosting rounds.\n",
      " |  \n",
      " |      max_depth :  Optional[int]\n",
      " |          Maximum tree depth for base learners.\n",
      " |      max_leaves :\n",
      " |          Maximum number of leaves; 0 indicates no limit.\n",
      " |      max_bin :\n",
      " |          If using histogram-based algorithm, maximum number of bins per feature\n",
      " |      grow_policy :\n",
      " |          Tree growing policy. 0: favor splitting at nodes closest to the node, i.e. grow\n",
      " |          depth-wise. 1: favor splitting at nodes with highest loss change.\n",
      " |      learning_rate : Optional[float]\n",
      " |          Boosting learning rate (xgb's \"eta\")\n",
      " |      verbosity : Optional[int]\n",
      " |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      " |      objective : typing.Union[str, typing.Callable[[numpy.ndarray, numpy.ndarray], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      " |          Specify the learning task and the corresponding learning objective or\n",
      " |          a custom objective function to be used (see note below).\n",
      " |      booster: Optional[str]\n",
      " |          Specify which booster to use: gbtree, gblinear or dart.\n",
      " |      tree_method: Optional[str]\n",
      " |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      " |          default, XGBoost will choose the most conservative option available.  It's\n",
      " |          recommended to study this option from the parameters document :doc:`tree method\n",
      " |          </treemethod>`\n",
      " |      n_jobs : Optional[int]\n",
      " |          Number of parallel threads used to run xgboost.  When used with other\n",
      " |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      " |          parallelize and balance the threads.  Creating thread contention will\n",
      " |          significantly slow down both algorithms.\n",
      " |      gamma : Optional[float]\n",
      " |          (min_split_loss) Minimum loss reduction required to make a further partition on a\n",
      " |          leaf node of the tree.\n",
      " |      min_child_weight : Optional[float]\n",
      " |          Minimum sum of instance weight(hessian) needed in a child.\n",
      " |      max_delta_step : Optional[float]\n",
      " |          Maximum delta step we allow each tree's weight estimation to be.\n",
      " |      subsample : Optional[float]\n",
      " |          Subsample ratio of the training instance.\n",
      " |      sampling_method :\n",
      " |          Sampling method. Used only by `gpu_hist` tree method.\n",
      " |            - `uniform`: select random training instances uniformly.\n",
      " |            - `gradient_based` select random training instances with higher probability when\n",
      " |              the gradient and hessian are larger. (cf. CatBoost)\n",
      " |      colsample_bytree : Optional[float]\n",
      " |          Subsample ratio of columns when constructing each tree.\n",
      " |      colsample_bylevel : Optional[float]\n",
      " |          Subsample ratio of columns for each level.\n",
      " |      colsample_bynode : Optional[float]\n",
      " |          Subsample ratio of columns for each split.\n",
      " |      reg_alpha : Optional[float]\n",
      " |          L1 regularization term on weights (xgb's alpha).\n",
      " |      reg_lambda : Optional[float]\n",
      " |          L2 regularization term on weights (xgb's lambda).\n",
      " |      scale_pos_weight : Optional[float]\n",
      " |          Balancing of positive and negative weights.\n",
      " |      base_score : Optional[float]\n",
      " |          The initial prediction score of all instances, global bias.\n",
      " |      random_state : Optional[Union[numpy.random.RandomState, int]]\n",
      " |          Random number seed.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      " |             it uses Hogwild algorithm.\n",
      " |  \n",
      " |      missing : float, default np.nan\n",
      " |          Value in the data which needs to be present as a missing value.\n",
      " |      num_parallel_tree: Optional[int]\n",
      " |          Used for boosting random forest.\n",
      " |      monotone_constraints : Optional[Union[Dict[str, int], str]]\n",
      " |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      " |          for more information.\n",
      " |      interaction_constraints : Optional[Union[str, List[Tuple[str]]]]\n",
      " |          Constraints for interaction representing permitted interactions.  The\n",
      " |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      " |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      " |          allowed to interact with each other.  See :doc:`tutorial\n",
      " |          </tutorials/feature_interaction_constraint>` for more information\n",
      " |      importance_type: Optional[str]\n",
      " |          The feature importance type for the feature_importances\\_ property:\n",
      " |  \n",
      " |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      " |            \"total_cover\".\n",
      " |          * For linear model, only \"weight\" is defined and it's the normalized coefficients\n",
      " |            without bias.\n",
      " |  \n",
      " |      gpu_id : Optional[int]\n",
      " |          Device ordinal.\n",
      " |      validate_parameters : Optional[bool]\n",
      " |          Give warnings for unknown parameter.\n",
      " |      predictor : Optional[str]\n",
      " |          Force XGBoost to use specific predictor, available choices are [cpu_predictor,\n",
      " |          gpu_predictor].\n",
      " |      enable_categorical : bool\n",
      " |  \n",
      " |          .. versionadded:: 1.5.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          Experimental support for categorical data.  When enabled, cudf/pandas.DataFrame\n",
      " |          should be used to specify categorical data type.  Also, JSON/UBJSON\n",
      " |          serialization format is required.\n",
      " |  \n",
      " |      feature_types : FeatureTypes\n",
      " |  \n",
      " |          .. versionadded:: 1.7.0\n",
      " |  \n",
      " |          Used for specifying feature types without constructing a dataframe. See\n",
      " |          :py:class:`DMatrix` for details.\n",
      " |  \n",
      " |      max_cat_to_onehot : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      " |          for categorical data.  When number of categories is lesser than the threshold\n",
      " |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      " |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      " |          categorical feature support. See :doc:`Categorical Data\n",
      " |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      " |  \n",
      " |      max_cat_threshold : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.7.0\n",
      " |  \n",
      " |          .. note:: This parameter is experimental\n",
      " |  \n",
      " |          Maximum number of categories considered for each split. Used only by\n",
      " |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      " |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      " |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      " |  \n",
      " |      eval_metric : Optional[Union[str, List[str], Callable]]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      " |          string or list of strings as names of predefined metric in XGBoost (See\n",
      " |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any other\n",
      " |          user defined metric that looks like `sklearn.metrics`.\n",
      " |  \n",
      " |          If custom objective is also provided, then custom metric should implement the\n",
      " |          corresponding reverse link function.\n",
      " |  \n",
      " |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      " |          object is provided, it's assumed to be a cost function and by default XGBoost will\n",
      " |          minimize the result during early stopping.\n",
      " |  \n",
      " |          For advanced usage on Early stopping like directly choosing to maximize instead of\n",
      " |          minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      " |  \n",
      " |          See :doc:`Custom Objective and Evaluation Metric </tutorials/custom_metric_obj>`\n",
      " |          for more.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |               This parameter replaces `eval_metric` in :py:meth:`fit` method.  The old one\n",
      " |               receives un-transformed prediction regardless of whether custom objective is\n",
      " |               being used.\n",
      " |  \n",
      " |          .. code-block:: python\n",
      " |  \n",
      " |              from sklearn.datasets import load_diabetes\n",
      " |              from sklearn.metrics import mean_absolute_error\n",
      " |              X, y = load_diabetes(return_X_y=True)\n",
      " |              reg = xgb.XGBRegressor(\n",
      " |                  tree_method=\"hist\",\n",
      " |                  eval_metric=mean_absolute_error,\n",
      " |              )\n",
      " |              reg.fit(X, y, eval_set=[(X, y)])\n",
      " |  \n",
      " |      early_stopping_rounds : Optional[int]\n",
      " |  \n",
      " |          .. versionadded:: 1.6.0\n",
      " |  \n",
      " |          Activates early stopping. Validation metric needs to improve at least once in\n",
      " |          every **early_stopping_rounds** round(s) to continue training.  Requires at least\n",
      " |          one item in **eval_set** in :py:meth:`fit`.\n",
      " |  \n",
      " |          The method returns the model from the last iteration (not the best one).  If\n",
      " |          there's more than one item in **eval_set**, the last entry will be used for early\n",
      " |          stopping.  If there's more than one metric in **eval_metric**, the last metric\n",
      " |          will be used for early stopping.\n",
      " |  \n",
      " |          If early stopping occurs, the model will have three additional fields:\n",
      " |          :py:attr:`best_score`, :py:attr:`best_iteration` and\n",
      " |          :py:attr:`best_ntree_limit`.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |              This parameter replaces `early_stopping_rounds` in :py:meth:`fit` method.\n",
      " |  \n",
      " |      callbacks : Optional[List[TrainingCallback]]\n",
      " |          List of callback functions that are applied at end of each iteration.\n",
      " |          It is possible to use predefined callbacks by using\n",
      " |          :ref:`Callback API <callback_api>`.\n",
      " |  \n",
      " |          .. note::\n",
      " |  \n",
      " |             States in callback are not preserved during training, which means callback\n",
      " |             objects can not be reused for multiple training sessions without\n",
      " |             reinitialization or deepcopy.\n",
      " |  \n",
      " |          .. code-block:: python\n",
      " |  \n",
      " |              for params in parameters_grid:\n",
      " |                  # be sure to (re)initialize the callbacks before each run\n",
      " |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      " |                  xgboost.train(params, Xy, callbacks=callbacks)\n",
      " |  \n",
      " |      kwargs : dict, optional\n",
      " |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      " |          can be found :doc:`here </parameter>`.\n",
      " |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      " |          dict simultaneously will result in a TypeError.\n",
      " |  \n",
      " |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      " |  \n",
      " |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      " |              that parameters passed via this argument will interact properly\n",
      " |              with scikit-learn.\n",
      " |  \n",
      " |          .. note::  Custom objective function\n",
      " |  \n",
      " |              A custom objective function can be provided for the ``objective``\n",
      " |              parameter. In this case, it should have the signature\n",
      " |              ``objective(y_true, y_pred) -> grad, hess``:\n",
      " |  \n",
      " |              y_true: array_like of shape [n_samples]\n",
      " |                  The target values\n",
      " |              y_pred: array_like of shape [n_samples]\n",
      " |                  The predicted values\n",
      " |  \n",
      " |              grad: array_like of shape [n_samples]\n",
      " |                  The value of the gradient for each sample point.\n",
      " |              hess: array_like of shape [n_samples]\n",
      " |                  The value of the second derivative for each sample point\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      XGBClassifier\n",
      " |      XGBModel\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, objective: Union[str, Callable[[numpy.ndarray, numpy.ndarray], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', use_label_encoder: Optional[bool] = None, **kwargs: Any) -> None\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X: Any, y: Any, *, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, eval_metric: Union[str, Sequence[str], Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]], NoneType] = None, early_stopping_rounds: Optional[int] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None, callbacks: Optional[Sequence[xgboost.callback.TrainingCallback]] = None) -> 'XGBClassifier'\n",
      " |      Fit gradient boosting classifier.\n",
      " |      \n",
      " |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      " |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      " |      pass ``xgb_model`` argument.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Feature matrix\n",
      " |      y :\n",
      " |          Labels\n",
      " |      sample_weight :\n",
      " |          instance weights\n",
      " |      base_margin :\n",
      " |          global bias for each instance.\n",
      " |      eval_set :\n",
      " |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      " |          metrics will be computed.\n",
      " |          Validation metrics will help us track the performance of the model.\n",
      " |      \n",
      " |      eval_metric : str, list of str, or callable, optional\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `eval_metric` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      " |      \n",
      " |      early_stopping_rounds : int\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `early_stopping_rounds` in :py:meth:`__init__` or\n",
      " |              :py:meth:`set_params` instead.\n",
      " |      verbose :\n",
      " |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      " |          measured on the validation set is printed to stdout at each boosting stage.\n",
      " |          If `verbose` is an integer, the evaluation metric is printed at each `verbose`\n",
      " |          boosting stage. The last boosting stage / the boosting stage found by using\n",
      " |          `early_stopping_rounds` is also printed.\n",
      " |      xgb_model :\n",
      " |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      " |          loaded before training (allows training continuation).\n",
      " |      sample_weight_eval_set :\n",
      " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      " |          object storing instance weights for the i-th validation set.\n",
      " |      base_margin_eval_set :\n",
      " |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      " |          object storing base margin for the i-th validation set.\n",
      " |      feature_weights :\n",
      " |          Weight for each feature, defines the probability of each feature being\n",
      " |          selected when colsample is being used.  All values must be greater than 0,\n",
      " |          otherwise a `ValueError` is thrown.\n",
      " |      \n",
      " |      callbacks :\n",
      " |          .. deprecated:: 1.6.0\n",
      " |              Use `callbacks` in :py:meth:`__init__` or :py:meth:`set_params` instead.\n",
      " |  \n",
      " |  predict(self, X: Any, output_margin: bool = False, ntree_limit: Optional[int] = None, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[int, int]] = None) -> numpy.ndarray\n",
      " |      Predict with `X`.  If the model is trained with early stopping, then `best_iteration`\n",
      " |      is used automatically.  For tree models, when data is on GPU, like cupy array or\n",
      " |      cuDF dataframe and `predictor` is not specified, the prediction is run on GPU\n",
      " |      automatically, otherwise it will run on CPU.\n",
      " |      \n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X :\n",
      " |          Data to predict with.\n",
      " |      output_margin :\n",
      " |          Whether to output the raw untransformed margin value.\n",
      " |      ntree_limit :\n",
      " |          Deprecated, use `iteration_range` instead.\n",
      " |      validate_features :\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin :\n",
      " |          Margin added to prediction.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      " |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      " |          are used in this prediction.\n",
      " |      \n",
      " |          .. versionadded:: 1.4.0\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction\n",
      " |  \n",
      " |  predict_proba(self, X: Any, ntree_limit: Optional[int] = None, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[int, int]] = None) -> numpy.ndarray\n",
      " |      Predict the probability of each `X` example being of a given class.\n",
      " |      \n",
      " |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like\n",
      " |          Feature matrix.\n",
      " |      ntree_limit : int\n",
      " |          Deprecated, use `iteration_range` instead.\n",
      " |      validate_features : bool\n",
      " |          When this is True, validate that the Booster's and data's feature_names are\n",
      " |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      " |      base_margin : array_like\n",
      " |          Margin added to prediction.\n",
      " |      iteration_range :\n",
      " |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      " |          random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      " |          20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      " |          used in this prediction.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          a numpy array of shape array-like of shape (n_samples, n_classes) with the\n",
      " |          probability of each data example being of a given class.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from XGBModel:\n",
      " |  \n",
      " |  __sklearn_is_fitted__(self) -> bool\n",
      " |  \n",
      " |  apply(self, X: Any, ntree_limit: int = 0, iteration_range: Optional[Tuple[int, int]] = None) -> numpy.ndarray\n",
      " |      Return the predicted leaf every tree for each sample. If the model is trained with\n",
      " |      early stopping, then `best_iteration` is used automatically.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like, shape=[n_samples, n_features]\n",
      " |          Input features matrix.\n",
      " |      \n",
      " |      iteration_range :\n",
      " |          See :py:meth:`predict`.\n",
      " |      \n",
      " |      ntree_limit :\n",
      " |          Deprecated, use ``iteration_range`` instead.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      " |          For each datapoint x in X and for each tree, return the index of the\n",
      " |          leaf x ends up in. Leaves are numbered within\n",
      " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      " |  \n",
      " |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      " |      Return the evaluation results.\n",
      " |      \n",
      " |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      " |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      " |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      " |      function.\n",
      " |      \n",
      " |      The returned evaluation result is a dictionary:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      " |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      evals_result\n",
      " |  \n",
      " |  get_booster(self) -> xgboost.core.Booster\n",
      " |      Get the underlying xgboost Booster of this model.\n",
      " |      \n",
      " |      This will raise an exception when fit was not called\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      booster : a xgboost booster of underlying model\n",
      " |  \n",
      " |  get_num_boosting_rounds(self) -> int\n",
      " |      Gets the number of xgboost boosting rounds.\n",
      " |  \n",
      " |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      " |      Get parameters.\n",
      " |  \n",
      " |  get_xgb_params(self) -> Dict[str, Any]\n",
      " |      Get xgboost specific parameters.\n",
      " |  \n",
      " |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      " |      Load the model from a file or bytearray. Path to file can be local\n",
      " |      or as an URI.\n",
      " |      \n",
      " |      The model is loaded from XGBoost format which is universal among the various\n",
      " |      XGBoost interfaces. Auxiliary attributes of the Python Booster object (such as\n",
      " |      feature_names) will not be loaded when using binary format.  To save those\n",
      " |      attributes, use JSON/UBJ instead.  See :doc:`Model IO </tutorials/saving_model>`\n",
      " |      for more info.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |        model.load_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.load_model(\"model.ubj\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname :\n",
      " |          Input file name or memory buffer(see also save_raw)\n",
      " |  \n",
      " |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      The model is saved in an XGBoost internal format which is universal among the\n",
      " |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      " |      (such as feature_names) will not be saved when using binary format.  To save\n",
      " |      those attributes, use JSON/UBJ instead. See :doc:`Model IO\n",
      " |      </tutorials/saving_model>` for more info.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |        model.save_model(\"model.json\")\n",
      " |        # or\n",
      " |        model.save_model(\"model.ubj\")\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or os.PathLike\n",
      " |          Output file name\n",
      " |  \n",
      " |  set_params(self, **params: Any) -> 'XGBModel'\n",
      " |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      " |      allow unknown kwargs. This allows using the full range of xgboost\n",
      " |      parameters that are not defined as member variables in sklearn grid\n",
      " |      search.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from XGBModel:\n",
      " |  \n",
      " |  best_iteration\n",
      " |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      " |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      " |  \n",
      " |  best_ntree_limit\n",
      " |  \n",
      " |  best_score\n",
      " |      The best score obtained by early stopping.\n",
      " |  \n",
      " |  coef_\n",
      " |      Coefficients property\n",
      " |      \n",
      " |      .. note:: Coefficients are defined only for linear learners\n",
      " |      \n",
      " |          Coefficients are only defined when the linear model is chosen as\n",
      " |          base learner (`booster=gblinear`). It is not defined for other base\n",
      " |          learner types, such as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Feature importances property, return depends on `importance_type`\n",
      " |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      " |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      " |      based on the importance type. For instance, if the importance type is\n",
      " |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      " |      trees.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      " |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      " |  \n",
      " |  feature_names_in_\n",
      " |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has feature\n",
      " |      names that are all strings.\n",
      " |  \n",
      " |  intercept_\n",
      " |      Intercept (bias) property\n",
      " |      \n",
      " |      .. note:: Intercept is defined only for linear learners\n",
      " |      \n",
      " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
      " |          learner (`booster=gblinear`). It is not defined for other base learner types,\n",
      " |          such as tree learners (`booster=gbtree`).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      " |  \n",
      " |  n_features_in_\n",
      " |      Number of features seen during :py:meth:`fit`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(XGBClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c33a0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st model should be with defult param \n",
    "xgb_model= XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0528de48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model with training data set \n",
    "xgb_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d06faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict over x_train & predict over x_test\n",
    "train_pred=xgb_model.predict(x_train)\n",
    "test_pred=xgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7954afbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_train,train_pred))\n",
    "print(accuracy_score(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7bafeb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_val_score() got an unexpected keyword argument 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#appling k_fold croass validation \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[1;32m----> 3\u001b[0m accuracy\u001b[38;5;241m=\u001b[39m\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_val_score() got an unexpected keyword argument 'x'"
     ]
    }
   ],
   "source": [
    "#appling k_fold croass validation \n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracy=cross_val_score(estimator= xgb_model, x=x, y=y, cv=5)\n",
    "accuracy.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c86e8aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix \n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(xgb_model,x_test,y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "353c8ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1050\n",
      "           1       1.00      1.00      1.00       981\n",
      "\n",
      "    accuracy                           1.00      2031\n",
      "   macro avg       1.00      1.00      1.00      2031\n",
      "weighted avg       1.00      1.00      1.00      2031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "748fff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyerpamater tunning \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb_model= XGBClassifier()\n",
    "param_grid={\"n_estimators\":[1,5,66,7,2,100],\"max_depth\":[3,4,5,6],\"gamma\":[0,1,2,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307941e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(xbg_model,param_grid,cv=5,scoring=\"accuracy\")\n",
    "grid.fit(x_train,y_train)\n",
    "\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f368057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importances\n",
    "grid.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a45cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_f=pd.DataFrame(index=x.columns,data=grid.best_estimator_.feature_importances_)\n",
    "imp_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d0b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_f.sort_values(\"Importances\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbadd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_f.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5fa9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_f=imp_f[imp_f[\"Importances\"]>0.000527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6),dpi=200)\n",
    "sns.barplot(data=imp_f.sort_values(\"Importance\"),x=imp_f.index,y=\"Importances\")\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618b8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eccf040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada3623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05922cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51afb51f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d03ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6a192e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ef10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d7b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98781e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff7dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299f16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67eb5d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
